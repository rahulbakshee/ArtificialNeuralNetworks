{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV data\n",
    "https://www.tensorflow.org/tutorials/load_data/csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are two main parts to this:\n",
    "\n",
    "-Loading the data off disk\n",
    "-Pre-processing it into a form suitable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\", header=None, \n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')\n",
    "\n",
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 953us/step - loss: 62.8422\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 934us/step - loss: 11.5633\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 953us/step - loss: 8.5166\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 7.9946\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 7.5338\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 953us/step - loss: 7.1693\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 6.8900\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 972us/step - loss: 6.6946\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 6.5701\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 6.4563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ad8d965220>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n",
    "\n",
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 953us/step - loss: 92.2074\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 52.4665\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 991us/step - loss: 15.6002\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 5.7161\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 972us/step - loss: 5.0669\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 972us/step - loss: 5.0343\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 4.9940\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 4.9883\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 972us/step - loss: 4.9615\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 991us/step - loss: 4.9235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ada34993a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprodessing\n",
    "normalize = preprocessing.Normalization()\n",
    "normalize.adapt(abalone_features)\n",
    "\n",
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# titanic\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'AddV2:0' shape=(None,) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Do a calculation using is\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <tf.Tensor 'sex:0' shape=(None, 1) dtype=string>,\n",
       " 'age': <tf.Tensor 'age:0' shape=(None, 1) dtype=float32>,\n",
       " 'n_siblings_spouses': <tf.Tensor 'n_siblings_spouses:0' shape=(None, 1) dtype=float32>,\n",
       " 'parch': <tf.Tensor 'parch:0' shape=(None, 1) dtype=float32>,\n",
       " 'fare': <tf.Tensor 'fare:0' shape=(None, 1) dtype=float32>,\n",
       " 'class': <tf.Tensor 'class:0' shape=(None, 1) dtype=string>,\n",
       " 'deck': <tf.Tensor 'deck:0' shape=(None, 1) dtype=string>,\n",
       " 'embark_town': <tf.Tensor 'embark_town:0' shape=(None, 1) dtype=string>,\n",
       " 'alone': <tf.Tensor 'alone:0' shape=(None, 1) dtype=string>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'normalization_1/truediv:0' shape=(None, 4) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "\n",
    "    lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "    one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "# tf.keras.utils.plot_model(model = titanic_preprocessing ,\n",
    "#                           to_file='model.png',\n",
    "#                           rankdir=\"LR\", \n",
    "#                           dpi=96, \n",
    "#                           show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}\n",
    "\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5682\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4929\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4635\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4464\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4357\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4298\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4258\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4231\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4219\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4208\n",
      "INFO:tensorflow:Assets written to: test\\assets\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x000002AF312DE1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x000002AF312D49D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x000002AF312BDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x000002AF312DE9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x000002AF312EA8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "                            layers.Dense(64),\n",
    "                            layers.Dense(1)\n",
    "                            ])\n",
    "\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam())\n",
    "    return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)\n",
    "\n",
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)\n",
    "\n",
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-2.029]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-2.029]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "# using tf.data\n",
    "# On in memory data\n",
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "    for i in itertools.count():\n",
    "        # For each feature take index `i`\n",
    "        example = {name:values[i] for name, values in features.items()}\n",
    "        yield example\n",
    "        \n",
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)\n",
    "\n",
    "for example in features_ds:\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4207\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4214\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4196\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4196\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2af2d92dca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))\n",
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)\n",
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# From a single file\n",
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'male' b'male']\n",
      "age                 : [57. 37. 29. 28. 28.]\n",
      "n_siblings_spouses  : [0 0 1 0 0]\n",
      "parch               : [0 1 0 0 0]\n",
      "fare                : [12.35  29.7   66.6   13.863  7.775]\n",
      "class               : [b'Second' b'First' b'First' b'Second' b'Third']\n",
      "deck                : [b'unknown' b'C' b'C' b'unknown' b'unknown']\n",
      "embark_town         : [b'Queenstown' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton']\n",
      "alone               : [b'y' b'n' b'n' b'y' b'y']\n",
      "\n",
      "label               : [0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)\n",
    "\n",
    "for batch, label in titanic_csv_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      "409600/405373 [==============================] - 1s 3us/step\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [281.68 271.71 289.12 296.31 275.34]\n",
      "rain_1h             : [0. 0. 0. 0. 0.]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [90 90 48 75 90]\n",
      "weather_main        : [b'Rain' b'Snow' b'Mist' b'Clouds' b'Drizzle']\n",
      "weather_description : [b'moderate rain' b'heavy snow' b'mist' b'broken clouds'\n",
      " b'light intensity drizzle']\n",
      "date_time           : [b'2013-04-22 17:00:00' b'2013-02-15 03:00:00' b'2013-08-01 02:00:00'\n",
      " b'2013-09-06 09:00:00' b'2012-12-16 04:00:00']\n",
      "\n",
      "label               : [5376  360  344 5297  271]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value[:5]}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 5.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 31s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Multiple files\n",
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts\\\\AGENCY.csv',\n",
       " 'fonts\\\\ARIAL.csv',\n",
       " 'fonts\\\\BAITI.csv',\n",
       " 'fonts\\\\BANKGOTHIC.csv',\n",
       " 'fonts\\\\BASKERVILLE.csv',\n",
       " 'fonts\\\\BAUHAUS.csv',\n",
       " 'fonts\\\\BELL.csv',\n",
       " 'fonts\\\\BERLIN.csv',\n",
       " 'fonts\\\\BERNARD.csv',\n",
       " 'fonts\\\\BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'LUCIDA' b'TEMPUS' b'QUICKTYPE' b'GOTHICE' b'VINETA' b'ERAS' b'TAI'\n",
      " b'BASKERVILLE' b'GOTHICE' b'HIGH TOWER']\n",
      "fontVariant         : [b'LUCIDA SANS UNICODE' b'TEMPUS SANS ITC' b'QUICKTYPE II MONO' b'GOTHICE'\n",
      " b'VINETA BT' b'ERAS MEDIUM ITC' b'MICROSOFT TAI LE'\n",
      " b'BASKERVILLE OLD FACE' b'GOTHICE' b'HIGH TOWER TEXT']\n",
      "m_label             : [9579  212   65 1088 8240   34 8218  183  366   96]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 0 0 1 1 0 0 1 0 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [34 20 33 55 36 35 75 51 26 39]\n",
      "m_left              : [20 23 22 28 32 24 23 27 27 31]\n",
      "originalH           : [67 66 47 52 53 11 15 11 64 13]\n",
      "originalW           : [ 67  46  37  46 125  13   8  12  50  12]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1   1   1 255   1   1   1   1]\n",
      "r0c1                : [  1   1   1   1  84 255   1   1   1   1]\n",
      "r0c2                : [  1   1   1   1 232 255   1   1   1   1]\n",
      "r0c3                : [  1   1   1   1 255 255   1   1   1 171]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)\n",
    "\n",
    "for features in fonts_ds.take(1):\n",
    "    for i, (name, value) in enumerate(features.items()):\n",
    "        if i>15:\n",
    "            break\n",
    "        print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Packing fields\n",
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "    image = [None]*400\n",
    "    new_feats = {}\n",
    "\n",
    "    for name, value in features.items():\n",
    "        match = re.match('r(\\d+)c(\\d+)', name)\n",
    "        if match:\n",
    "            image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "        else:\n",
    "            new_feats[name] = value\n",
    "\n",
    "    image = tf.stack(image, axis=0)\n",
    "    image = tf.reshape(image, [20, 20, -1])\n",
    "    new_feats['image'] = image\n",
    "\n",
    "    return new_feats\n",
    "\n",
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "    plt.subplot(3,3,n+1)\n",
    "    plt.imshow(features['image'][..., n])\n",
    "    plt.title(chr(features['m_label'][n]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower level functions\n",
    "\n",
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: int32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types) \n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "    return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonts\\\\AGENCY.csv'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "    print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "     b'fonts\\\\SNAP.csv'\n",
      "     b'fonts\\\\GOTHICE.csv'\n",
      "     b'fonts\\\\SEGOE.csv'\n",
      "     b'fonts\\\\JUICE.csv'\n",
      "     b'fonts\\\\FRENCH.csv'\n",
      "    ...\n",
      "\n",
      "Epoch 2:\n",
      "     b'fonts\\\\GOUDY.csv'\n",
      "     b'fonts\\\\MV_BOLI.csv'\n",
      "     b'fonts\\\\PALACE.csv'\n",
      "     b'fonts\\\\PAPYRUS.csv'\n",
      "     b'fonts\\\\CONSTANTIA.csv'\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-2d579090c868>:14: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  fonts_dict['character'].append(chr(row[2].numpy()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNTRYBLUEPRINT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIMES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DUTCH801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COUNTRYBLUEPRINT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIMES</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DUTCH801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COUNTRYBLUEPRINT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TIMES</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DUTCH801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COUNTRYBLUEPRINT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          font_name character\n",
       "0  COUNTRYBLUEPRINT         \n",
       "1             TIMES         2\n",
       "2          DUTCH801         \n",
       "3  COUNTRYBLUEPRINT         \n",
       "4             TIMES         7\n",
       "5          DUTCH801         \n",
       "6  COUNTRYBLUEPRINT         \n",
       "7             TIMES         R\n",
       "8          DUTCH801         \n",
       "9  COUNTRYBLUEPRINT         "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_font_csv_ds(path):\n",
    "    return tf.data.experimental.CsvDataset(\n",
    "    path, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)\n",
    "\n",
    "font_rows = font_files.interleave(make_font_csv_ds,\n",
    "                                  cycle_length=3)\n",
    "\n",
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "    fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "    fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance\n",
    "\n",
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 7.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "    print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "    print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
