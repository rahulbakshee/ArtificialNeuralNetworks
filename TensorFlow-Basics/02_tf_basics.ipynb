{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 TensorFlow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the part of basics of Tensorflow playground. These ilustrations are inspired from lecture notes of CS 20SI: Tensorflow for Deep Learning Research.I do not own this code.\n",
    "For more info visit \n",
    "http://web.stanford.edu/class/cs20si/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most of the operations are same as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "shape (2, 3)\n"
     ]
    }
   ],
   "source": [
    "zer = tf.zeros([2,3], tf.int32)\n",
    "print(sess.run(zer))\n",
    "print(\"shape\", zer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_like [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# we can get tensors of zeros / ones like another tensor \n",
    "input_tensor = [[0,], [1], [2], [3]]\n",
    "zer_like = tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)\n",
    "print(\"zero_like\", sess.run(zer_like))\n",
    "# same goes for  tf.ones_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.  8.  8.  8.]\n",
      " [ 8.  8.  8.  8.]\n",
      " [ 8.  8.  8.  8.]]\n"
     ]
    }
   ],
   "source": [
    "# we can create a tensor filled with user given values using tf.fill(dims,valu,name=None)\n",
    "print(sess.run(tf.fill([3,4], 8.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linspace     [ 10.  11.  12.  13.]\n",
      "range      [ 3  6  9 12 15]\n",
      "-----------\n",
      "NOTE: important thing to note here is tensorflow sequences are not iterable(like in numpy)\n"
     ]
    }
   ],
   "source": [
    "# You can create sequences of evenly spaced values begining at start ending at stop\n",
    "# tf.linspace(start, stop, num, name=None)\n",
    "linsp = tf.linspace(10.0, 13.0, 4, name='linsp')\n",
    "print(\"linspace    \", sess.run(linsp))\n",
    "\n",
    "# tf.range(start, limit=None, delta=1, dtype=None, name='range')\n",
    "# stop number is no included\n",
    "print(\"range     \", sess.run(tf.range(3, 18, 3)))\n",
    "print(\"-----------\")\n",
    "print(\"NOTE: important thing to note here is tensorflow sequences are not iterable(like in numpy)\")\n",
    "#for _ in np.linspace(0,10,4) # works fine\n",
    "#for _ in tf.linspace(0,10,4) # TypeError(\"'Tensor' object is not iterable.\")\n",
    "\n",
    "#for _ in range(4) # OK\n",
    "#for _ in tf.range(4) # TypeError(\"'Tensor' object is not iterable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the times, you can use TensorFlow types and NumPy types interchangeably\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Note 1** : There is a catch here for string data types. For numeric and boolean types, TensorFlow and NumPy dtypes match down the line. However, tf.string does not have an exact match in NumPy due to the way NumPy handles strings. TensorFlow can still import string arrays from NumPy perfectly fine -- just don’t specify a dtype in NumPy!\n",
    "\n",
    "* **Note 2** : Both TensorFlow and NumPy are n-d array libraries. NumPy supports ndarray, but doesn’t offer methods to create tensor functions and automatically compute derivatives, nor GPU support. So TensorFlow still wins!\n",
    "\n",
    "* **Note 3**: Using Python types to specify TensorFlow objects is quick and easy, and it is useful for prototyping ideas. However, there is an important pitfall in doing it this way.  Python types lack  the ability to explicitly state the data type, but TensorFlow’s data types are more specific. For example, all integers are the same type, but TensorFlow has 8-bit, 16-bit, 32-bit, and 64-bit integers available. \n",
    "\n",
    "* Therefore, if you use a Python type, TensorFlow has to infer which data type you mean. It’s possible to convert the data into the appropriate type when you pass it into TensorFlow, but certain data types still may be difficult to declare correctly, such as complex numbers. Because of this, it is common to create hand-defined Tensor objects as NumPy arrays.\n",
    "\n",
    "* So, always use TensorFlow types whenever possible, because both TensorFlow and NumPy can evolve to a point that such compatibility no longer exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more on constants, variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To declare a variable, you create an instance of the class tf.Variable. Note that it’s tf.constant but\n",
    "tf.Variable and not tf.variable because tf.constant is an op, while tf.Variable is a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between a constant and a variable:\n",
    "* A constant is constant. A variable can be assigned to, its value can be changed.\n",
    "* A constant's value is stored in the graph and its value is replicated wherever the graph is\n",
    "loaded. A variable is stored separately, and may live on a parameter server.\n",
    "\n",
    "Point 2 basically means that constants are stored in the graph definition. When constants are\n",
    "memory expensive, it will be slow each time you have to load the graph. To see the graph’s\n",
    "definition and what’s stored in the graph’s definition, simply print out the graph’s protobuf.\n",
    "Protobuf stands for protocol buffer , “Google's language-neutral, platform-neutral, extensible\n",
    "mechanism for serializing structured data – think XML, but smaller, faster, and simpler.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of w (784, 10)\n"
     ]
    }
   ],
   "source": [
    "# We can create a tf.Variable w as 784 x 10 tensor filled with zeros\n",
    "\n",
    "w = tf.Variable(tf.zeros([784,10])) \n",
    "print(\"shape of w\", w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable holds several ops:\n",
    "\n",
    "`\n",
    "x = tf.Variable(...) ==>\n",
    "x.initializer # init\n",
    "x.value() # read op\n",
    "x.assign(...) # write op\n",
    "x.assign_add(...)\n",
    ".....and more\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to initialize the variables before using them\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "   sess.run(init)\n",
    "\n",
    "\n",
    "# Note that you use sess.run() to run the initializer, not fetching any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  1\n",
      "b  0.5\n",
      "shape of w   (784, 10)\n"
     ]
    }
   ],
   "source": [
    "# To initialize only a subset of variables, you use tf.variables_initializer() with a list of variables you want to initialize:\n",
    "a = tf.Variable(1, dtype=tf.int32)\n",
    "b = tf.Variable(0.5, dtype=tf.float32)\n",
    "c = tf.Variable(10.3, dtype=tf.float64)\n",
    "\n",
    "init = tf.variables_initializer([a,b], name=\"init\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"a \",sess.run(a))\n",
    "    print(\"b \",sess.run(b))\n",
    "    # print(\"c \",sess.run(c)) # throws error \"Attempting to use uninitialized value Variable\"\n",
    "\n",
    "# You can also initialize each variable separately using  tf.Variable.initializer \n",
    "\n",
    "W = tf.Variable(tf.zeros ([ 784 , 10 ])) #create variable W as 784 x 10 tensor, filled with zeros\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(\"shape of w  \", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not evaluating correctly  <tf.Variable 'Variable_5:0' shape=(4, 2) dtype=float32_ref>\n",
      "evaluating correctly  [[-0.23452228  0.11243899]\n",
      " [-0.66670126 -1.20581996]\n",
      " [ 1.74655235 -0.82684875]\n",
      " [-0.04403993 -1.0582459 ]]\n"
     ]
    }
   ],
   "source": [
    "# to evaluate a variable we use .eval() method\n",
    "x = tf.Variable(tf.truncated_normal([4,2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    print(\"not evaluating correctly \", x) # wont print the value of x, rather it will print Tensor(\"Variable/read:0\",shape =(700,10),dtype=float32)\n",
    "    print(\"evaluating correctly \",x.eval()) # will print the value of variable x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should print new value 100, but printed old value  10\n",
      "new value  100\n"
     ]
    }
   ],
   "source": [
    "# assign values to variables-->the incorrect way:\n",
    "\n",
    "w = tf.Variable(10)\n",
    "w.assign(100)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(w.initializer)\n",
    "    print(\"should print new value 100, but printed old value \",w.eval()) #prints 10 not 100 why!!!!! \n",
    "    \n",
    "    # w.assign(100) doesn't assign the value 100 to w, but instead it creates an assign op to do that. \n",
    "    # we have to run this assign op in session\n",
    "\n",
    "    # assign values to variables-->the correct way:\n",
    "\n",
    "    w = tf.Variable(10)\n",
    "    assign_op = w.assign(100)\n",
    "    sess.run(assign_op)\n",
    "    #dont need a sess.run(w.initilizer) here, assign() will do that for us.\n",
    "    #infact, initilizer op is the assign op which assigns the initial value to variable.\n",
    "    print(\"new value \", w.eval()) # prints 100\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# multiple sessions maintain separate values \n",
    "w = tf.Variable(10)\n",
    "\n",
    "sess1 = tf.Session()\n",
    "sess2 = tf.Session()\n",
    "\n",
    "sess1.run(w.initializer)\n",
    "sess2.run(w.initializer)\n",
    "\n",
    "print(sess1.run(w.assign_add(10))) # prints 20\n",
    "print(sess2.run(w.assign_sub(2))) # prints 8\n",
    "\n",
    "sess1.close()\n",
    "sess2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a variable that depends on other variable\n",
    "w = tf.Variable(tf.truncated_normal([700,10]))\n",
    "u = tf.Variable(w*2)\n",
    "\n",
    "#to intialize\n",
    "u = tf.Variable(w.initialized_value() * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# tf.InteractiveSession()\n",
    "# interactive session makes itself default one. Then we can call eval/run without calling like sess.eval\n",
    "sess_int = tf.InteractiveSession()\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(6)\n",
    "c = a * b\n",
    "\n",
    "print(c.eval()) # we can use this without passing sess\n",
    "\n",
    "sess_int.close() #close the interactive session\n",
    "\n",
    "# tf.InteractiveSession().close() closes the interactive session.\n",
    "# tf.get_default_session() returns the default session for the current thread.\n",
    "# The returned session will be inner most session on which \"as Session\" or Session.as_default() context has been entered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Handle dependencies within a graph\n",
    "suppose our graph has 5 ops a,b,c,d,e \n",
    "we can handle dependencies by giving the order of execution\n",
    "`\n",
    "```\n",
    "with g.control_dependencies([a,b,c,d,e]):\n",
    "   #d and e will only run after a,b,c have executed\n",
    "\td = ....\n",
    "\ta = .....\n",
    "\te = .....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`To print graph definition `\n",
    "\n",
    "> print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample example on variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "16\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.Variable(2, name='scaler')\n",
    "\n",
    "a_times_two = a.assign(a*2)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as ses:\n",
    "    ses.run(init)\n",
    "    print(ses.run(a_times_two)) # prints 4\n",
    "    print(ses.run(a_times_two)) # prints 8\n",
    "    print(ses.run(a_times_two)) # prints 16\n",
    "    print(ses.run(a_times_two - a.assign_sub(32))) # prints 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
