{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Classification of MNIST dataset using Convolutional Neural Networks -CNN and TensorFlow`\n",
    "Till now, for classifying the MNIST dataset we have seen single layer perceptron giving test accuracy ~ .92\n",
    "\n",
    "Multilayer network with 2 hidden layers got us test accuracy ~ .95  (both not good for the real world problems)\n",
    "\n",
    "Now we are going to understand how to tie \"convolution\",\"pooling\", \"Relu\", \"fc\" (fully-connected) and \"softmax\" layers together.\n",
    "\n",
    "This model gives Test Accuracy of .99\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 21\n",
    "np.random.seed = seed\n",
    "\n",
    "# import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params\n",
    "NUM_CLASS = 10\n",
    "INPUT_SIZE = 28\n",
    "INPUT_SIZE_FLAT = INPUT_SIZE * INPUT_SIZE\n",
    "\n",
    "# network params\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.6\n",
    "BATCH_SIZE = 100\n",
    "TRAINING_EPOCHS = 200000\n",
    "DISPLAY_STEP = 100\n",
    "\n",
    "\n",
    "# input placeholders\n",
    "images = tf.placeholder(tf.float32, [None, INPUT_SIZE_FLAT], name=\"images\")\n",
    "labels = tf.placeholder(tf.float32, [None, NUM_CLASS], name=\"labels\")\n",
    "keep_prob = tf.placeholder(tf.float32, name='dropout')\n",
    "\n",
    "# network params\n",
    "weights = {\n",
    "    # 5x5 conv filter size, 1 in_channel, 32 out_channel \n",
    "    'conv1_w': tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1, seed=seed,name=\"conv1_w\")),\n",
    "    \n",
    "    # 5x5 conv filter size, 32 in_channel, 64 out_channel\n",
    "    'conv2_w': tf.Variable(tf.truncated_normal([5,5,32,64], stddev=0.1, seed=seed, name=\"conv2_w\")),\n",
    "    \n",
    "    # fully connected layer, 7*7*64 inputs, 1024 output\n",
    "    'fc_w': tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev=0.1, seed=seed, name=\"fc_w\")),\n",
    "    \n",
    "    # output layer(softmax layer), 1024 inputs, 10 outputs [NUM_CLASS]\n",
    "    'soft_w': tf.Variable(tf.truncated_normal([1024, NUM_CLASS], stddev=0.1, seed=seed, name=\"softmax_w\"))\n",
    "}\n",
    "biases = {\n",
    "    # number of biases for conv1 layer = out_channels\n",
    "    'conv1_b': tf.Variable(tf.random_normal([32], stddev=0.1, seed=seed, name=\"conv1_b\")),\n",
    "    \n",
    "    # number of bias for conv2 layer = out_channel\n",
    "    'conv2_b': tf.Variable(tf.random_normal([64], stddev=0.1, seed=seed, name=\"conv2_b\")),\n",
    "    \n",
    "    # number of bias for fc layer = output\n",
    "    'fc_b': tf.Variable(tf.random_normal([1024], stddev=0.1, seed=seed, name=\"fc_b\")),\n",
    "    \n",
    "    # number of bias for softmax(output) layer\n",
    "    'soft_b': tf.Variable(tf.random_normal([10],stddev=0.1, seed=seed, name=\"soft_b\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model \n",
    "### `conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### convolutional layer1 #######\n",
    "# reshape the input from (2d)[28x28] to (4d)[BATCH_SIZE, in_height, in_width, in_channels]\n",
    "images_reshaped = tf.reshape(images, shape=[-1, 28, 28, 1], name=\"reshape_input\")\n",
    "# conv\n",
    "conv1 = tf.nn.conv2d(input=images_reshaped, filter=weights[\"conv1_w\"], strides=[1,1,1,1], padding='SAME')\n",
    "# relu\n",
    "conv1 = tf.nn.relu(features=(conv1+biases[\"conv1_b\"]))\n",
    "# pool\n",
    "conv1 = tf.nn.max_pool(value=conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=\"output_of_conv1\")\n",
    "# output dimension => BATCH_SIZE x 14 x 14 x 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### convolutional layer2 #######\n",
    "# conv\n",
    "conv2 = tf.nn.conv2d(input=conv1, filter=weights[\"conv2_w\"], strides=[1,1,1,1], padding='SAME')\n",
    "# relu\n",
    "conv2 = tf.nn.relu(features=(conv2+biases[\"conv2_b\"]))\n",
    "# pool\n",
    "conv2 = tf.nn.max_pool(value=conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=\"output_of_conv2\")\n",
    "# output dimension => BATCH_SIZE x 7 x 7 x 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### fully connected layer #######\n",
    "# reshape output of conv2(4d) to (2d) to be used by fully connected layer\n",
    "fc = tf.reshape(tensor=conv2, shape=[-1, weights[\"fc_w\"].get_shape().as_list()[0]], name=\"fc_reshape\")\n",
    "\n",
    "# fc \n",
    "fc = tf.add(tf.matmul(fc,weights[\"fc_w\"]), biases[\"fc_b\"])\n",
    "# relu\n",
    "fc = tf.nn.relu(fc)\n",
    "# dropout\n",
    "fc = tf.nn.dropout(fc, keep_prob=keep_prob, seed=seed, name=\"output_of_fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### softmax layer #######\n",
    "logits = tf.add(tf.matmul(fc, weights[\"soft_w\"]), biases[\"soft_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "# loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "# optimizer \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE,name='Adam').minimize(loss)\n",
    "# accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10000, batch_loss 0.1410, acc 0.96\n",
      "iter 20000, batch_loss 0.0479, acc 0.99\n",
      "iter 30000, batch_loss 0.0762, acc 0.98\n",
      "iter 40000, batch_loss 0.0860, acc 0.99\n",
      "iter 50000, batch_loss 0.1040, acc 0.98\n",
      "iter 60000, batch_loss 0.0089, acc 1.0\n",
      "iter 70000, batch_loss 0.0148, acc 0.99\n",
      "iter 80000, batch_loss 0.0067, acc 1.0\n",
      "iter 90000, batch_loss 0.0178, acc 1.0\n",
      "iter 100000, batch_loss 0.0326, acc 0.99\n",
      "iter 110000, batch_loss 0.0093, acc 1.0\n",
      "iter 120000, batch_loss 0.0073, acc 1.0\n",
      "iter 130000, batch_loss 0.0257, acc 0.99\n",
      "iter 140000, batch_loss 0.0198, acc 0.99\n",
      "iter 150000, batch_loss 0.0039, acc 1.0\n",
      "iter 160000, batch_loss 0.0071, acc 1.0\n",
      "iter 170000, batch_loss 0.0148, acc 1.0\n",
      "iter 180000, batch_loss 0.0038, acc 1.0\n",
      "iter 190000, batch_loss 0.0119, acc 1.0\n",
      "optimization finished\n",
      "Testing accuracy  0.9906\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * BATCH_SIZE < TRAINING_EPOCHS:\n",
    "        batch_images, batch_labels = mnist.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(fetches=optimizer, feed_dict={images:batch_images, labels:batch_labels, keep_prob:DROPOUT})\n",
    "        \n",
    "        if step % DISPLAY_STEP == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            los, acc = sess.run([loss, accuracy], feed_dict={images:batch_images, labels:batch_labels, keep_prob:1.0})\n",
    "            \n",
    "            print(\"iter \" + str(step*BATCH_SIZE) + \", batch_loss \" + \"{:.4f}\".format(los) + \", acc \"+ \"{:.4}\".format(acc))\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    print(\"optimization finished\")\n",
    "    \n",
    "    # time to calculate test accuracy\n",
    "    print(\"Testing accuracy \", sess.run(fetches=accuracy,feed_dict={images:mnist.test.images, \n",
    "                                                                    labels:mnist.test.labels,\n",
    "                                                                    keep_prob:1.0}))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `some new terminologies we used in this code `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.conv2d\n",
    "`tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)`\n",
    "\n",
    "This computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "* Input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "* Filter / kernel tensor of shape `[filter_height, filter_width, in_channels, out_channels]`\n",
    "* Strides of shape [1,stride,stride,1] must have `strides[0] = strides[3] = 1`.  \n",
    "* For the most common case of the same horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
    "* Padding is `SAME` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.relu\n",
    "`tf.nn.relu(features, name=None)`\n",
    "\n",
    "This computes rectified linear: `max(features, 0)`.\n",
    "* features is input tensor (mostly the output of conv layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.max_pool\n",
    "`tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None) `\n",
    "\n",
    "This performs the max pooling on the input.\n",
    "* value: A 4-D `Tensor` with shape `[batch, height, width, channels]` and type `tf.float32`.\n",
    "* ksize: A list of ints that has length >= 4.  The size of the window for each dimension of the input tensor.\n",
    "* strides: A list of ints that has length >= 4.  The stride of the sliding window for each dimension of the input tensor.\n",
    "* padding: A string, either `'VALID'` or `'SAME'`. The padding algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.dropout\n",
    "` tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None)`\n",
    "\n",
    "This computes dropout\n",
    "* x: A tensor.\n",
    "* keep_prob: A scalar `Tensor` with the same type as x. The probability that each element is kept.\n",
    "* noise_shape: A 1-D `Tensor` of type `int32`, representing the shape for randomly generated keep/drop flags.\n",
    "* seed: A Python random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reshape\n",
    "`tf.reshape(tensor, shape, name=None)`\n",
    "\n",
    "* Given `tensor`, this operation returns a tensor that has the same values as `tensor` with shape `shape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
